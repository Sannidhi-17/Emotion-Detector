{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import all the libraries\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPooling2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import images and clssify the number of classification\n",
    "\n",
    "num_classes = 6\n",
    "img_row, img_col = 48, 48\n",
    "batch_size = 16\n",
    "train_data_dir = './fer2013/train' \n",
    "test_data_dir = './fer2013/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28273 images belonging to 6 classes.\n",
      "Found 3534 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# let's use some data Augmentation\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  rotation_range = 30,\n",
    "                                  shear_range = 0.3,\n",
    "                                  zoom_range = 0.3,\n",
    "                                  width_shift_range =0.4,\n",
    "                                  height_shift_range = 0.4,\n",
    "                                  horizontal_flip = True,\n",
    "                                  fill_mode = 'nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                   color_mode = 'grayscale',\n",
    "                                                   target_size = (img_row, img_col),\n",
    "                                                   batch_size = batch_size,\n",
    "                                                   class_mode = 'categorical',\n",
    "                                                   shuffle = True)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(test_data_dir,\n",
    "                                                             color_mode = 'grayscale',\n",
    "                                                   target_size = (img_row, img_col),\n",
    "                                                   batch_size = batch_size,\n",
    "                                                   class_mode = 'categorical',\n",
    "\n",
    "                                                              shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import keras and layers\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Little VGG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 6, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 6, 6, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 390       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 1,328,102\n",
      "Trainable params: 1,325,926\n",
      "Non-trainable params: 2,176\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create the VGG model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#Block - 1\n",
    "model.add(Conv2D(32, (3,3), padding ='same', kernel_initializer = 'he_normal', input_shape = (img_row, img_col, 1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3,3), padding ='same', kernel_initializer = 'he_normal', input_shape = (img_row, img_col, 1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#Block - 2\n",
    "model.add(Conv2D(64, (3,3), padding ='same', kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3), padding ='same', kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#Block - 3\n",
    "model.add(Conv2D(128, (3,3), padding ='same', kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3,3), padding ='same', kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#Block - 4\n",
    "model.add(Conv2D(256, (3,3), padding ='same', kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3,3), padding ='same', kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#Block - 5\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#Block - 6\n",
    "model.add(Dense(64, kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#Block - 7\n",
    "model.add(Dense(num_classes, kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"/home/deeplearningcv/DeepLearningCV/Trained Models/emotion_little_vgg_3.h5\",\n",
    "                            monitor = 'val_loss', mode = 'min', save_best_only =True, verbose = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 3, verbose = 1, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 3, verbose = 1, min_delta = 0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [earlystop, checkpoint, reduce_lr]\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = Adam(lr = 0.001), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = 28273\n",
    "nb_validation_samples = 3534\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sannidhi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Sannidhi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., steps_per_epoch=1767, epochs=1, validation_steps=3534)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1767/1767 [==============================] - 842s 477ms/step - loss: 1.9731 - accuracy: 0.2085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1fb5f44cbc8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, samples_per_epoch = nb_train_samples, nb_epoch = epochs, nb_val_samples = nb_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3534 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "nb_train_samples = 28273\n",
    "nb_validation_samples = 3534\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(test_data_dir,\n",
    "                                                             color_mode = 'grayscale',\n",
    "                                                   target_size = (img_row, img_col),\n",
    "                                                   batch_size = batch_size,\n",
    "                                                   class_mode = 'categorical',\n",
    "                                                   shuffle = True)\n",
    "\n",
    "class_labels = validation_generator.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "classes = list(class_labels.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_generator(validation_generator, nb_validation_samples // batch_size + 1)\n",
    "y_pred = np.argmax(y_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[  0   0 486   4   1   0]\n",
      " [  0   0 520   5   3   0]\n",
      " [  0   0 868   8   3   0]\n",
      " [  0   0 620   4   2   0]\n",
      " [  0   0 582   8   3   1]\n",
      " [  0   0 415   0   1   0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificatio Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.00      0.00      0.00       491\n",
      "        Fear       0.00      0.00      0.00       528\n",
      "       Happy       0.25      0.99      0.40       879\n",
      "     Neutral       0.14      0.01      0.01       626\n",
      "         Sad       0.23      0.01      0.01       594\n",
      "    Surprise       0.00      0.00      0.00       416\n",
      "\n",
      "    accuracy                           0.25      3534\n",
      "   macro avg       0.10      0.17      0.07      3534\n",
      "weighted avg       0.13      0.25      0.10      3534\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sannidhi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Classificatio Report\")\n",
    "target_names = list(class_labels.values())\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names = target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "cnf_matrix = confusion_matrix(validation_generator.classes, y_pred)\n",
    "plt.imshow(cnf_matrix, interpolation = 'nearest')\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(len(classes))\n",
    "_ = plt.xticks(tick_marks, classes, rotation=90)\n",
    "_ = plt.yticks(tick_marks, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is save\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model.h5\")\n",
    "print(\"Model is save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3534 images belonging to 6 classes.\n",
      "{0: 'Angry', 1: 'Fear', 2: 'Happy', 3: 'Neutral', 4: 'Sad', 5: 'Surprise'}\n"
     ]
    }
   ],
   "source": [
    "# Get the class labels\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(test_data_dir,\n",
    "                                                             color_mode = 'grayscale',\n",
    "                                                   target_size = (img_row, img_col),\n",
    "                                                   batch_size = batch_size,\n",
    "                                                   class_mode = 'categorical',\n",
    "                                                   shuffle = True)\n",
    "\n",
    "class_labels = validation_generator.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on Validation Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sannidhi\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:104: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "\n",
    "def draw_test(name, pred, im, true_label):\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(im, 160, 0, 0, 300 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    cv2.putText(expanded_image, \"predited - \"+ pred, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
    "    cv2.putText(expanded_image, \"true - \"+ true_label, (20, 120) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "\n",
    "def getRandomImage(path, img_width, img_height):\n",
    "    \"\"\"function loads a random images from a random folder in our test path \"\"\"\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    file_path = path + path_class\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    final_path = file_path + \"/\" + image_name\n",
    "    return image.load_img(final_path, target_size = (img_width, img_height),grayscale=True), final_path, path_class\n",
    "\n",
    "# dimensions of our images\n",
    "img_width, img_height = 48, 48\n",
    "\n",
    "# We use a very small learning rate \n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = RMSprop(lr = 0.001),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "files = []\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "# predicting images\n",
    "for i in range(0, 10):\n",
    "    path = './fer2013/validation/' \n",
    "    img, final_path, true_label = getRandomImage(path, img_width, img_height)\n",
    "    files.append(final_path)\n",
    "    true_labels.append(true_label)\n",
    "    x = image.img_to_array(img)\n",
    "    x = x * 1./255\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict_classes(images, batch_size = 10)\n",
    "    predictions.append(classes)\n",
    "    \n",
    "for i in range(0, len(files)):\n",
    "    image = cv2.imread((files[i]))\n",
    "    image = cv2.resize(image, None, fx=3, fy=3, interpolation = cv2.INTER_CUBIC)\n",
    "    draw_test(\"Prediction\", class_labels[predictions[i][0]], image, true_labels[i])\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    " \n",
    "# load model\n",
    "classifier = load_model('model.h5')\n",
    "print(\"xxx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
